{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.metrics import fbeta_score\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import fbeta_score\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "import time\n",
    "%matplotlib inline\n",
    "pal = sns.color_palette()\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#Load train and test CSVs\n",
    "df_train = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\n",
    "df_test = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore train labels distribution\n",
    "labels = df_train['tags'].apply(lambda x: x.split(' '))\n",
    "from collections import Counter, defaultdict\n",
    "counts = defaultdict(int) #dictionary containing each individual label\n",
    "for l in labels:\n",
    "    for l2 in l:\n",
    "        counts[l2] += 1\n",
    "tag_list=list(counts.keys()) \n",
    "y=list(counts.values())\n",
    "sns.barplot(x=tag_list, y=y);\n",
    "plt.xlabel('labels');\n",
    "plt.xticks(rotation = 90);\n",
    "plt.title('Tag count for train set');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore test labels distribution\n",
    "labels_test = df_test['tags'].apply(lambda x: x.split(' '))\n",
    "from collections import Counter, defaultdict\n",
    "counts_test = defaultdict(int)\n",
    "for l in labels_test:\n",
    "    for l2 in l:\n",
    "        counts_test[l2] += 1\n",
    "\n",
    "tag_list_test=list(counts_test.keys()) \n",
    "test_count=list(counts_test.values())\n",
    "sns.barplot(x=tag_list_test, y=test_count);\n",
    "plt.xlabel('labels');\n",
    "plt.xticks(rotation = 90);\n",
    "plt.title('Tag counts for test set');\n",
    "\n",
    "#These are not actual labels, just placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View some of the train images\n",
    "\n",
    "new_style = {'grid': False}\n",
    "plt.rc('axes', **new_style)\n",
    "_, ax = plt.subplots(3, 3, sharex='col', sharey='row', figsize=(20, 20))\n",
    "i = 0\n",
    "for f, l in df_train[:9].values:\n",
    "    img = cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(f))\n",
    "    ax[i // 3, i % 3].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax[i // 3, i % 3].set_title('{} - {}'.format(f, l))\n",
    "    #ax[i // 4, i % 4].show()\n",
    "    i += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dictionary assigning a numerical value to each label\n",
    "label_map = {i:j for j, i in enumerate(tag_list)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the training labels. Convert the images into pixels and resize them\n",
    "X_train, Y_train = [], []\n",
    "for img, label in tqdm(df_train.values, miniters = 1000):\n",
    "  target = np.zeros(17)\n",
    "  for tag in label.split(' '):\n",
    "    target[label_map[tag]]=1\n",
    "  X_train.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img)), (64,64)))\n",
    "  Y_train.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the test images to pixels and resize them as well\n",
    "X_test=[]\n",
    "for img, label in tqdm(df_test[:40669].values, miniters = 1000):\n",
    "  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img)), (64,64)))\n",
    "for img, label in tqdm(df_test[40669:].values, miniters = 1000):\n",
    "  X_test.append(cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img)), (64,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confirm the dimensions\n",
    "len(X_test), len(X_train), len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change lists to numpy arrays and normalize\n",
    "x_train = np.array(X_train, np.float16)/255\n",
    "y_train = np.array(Y_train, np.uint8)\n",
    "x_test = np.array(X_test, np.float16)/255\n",
    "#split the train data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n",
    "print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a function to calculate the fbeta score\n",
    "def fbeta(y_true, y_pred, threshold_shift=0):\n",
    "    beta = 2\n",
    "    y_pred = K.clip(y_pred, 0, 1)\n",
    "    y_pred_bin = K.round(y_pred + threshold_shift)\n",
    "    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n",
    "    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    beta_squared = beta ** 2\n",
    "    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())\n",
    "\n",
    "#Train a network with 2 convolution layers, 2 pooling layers, 1 fully connected layer, and one output layer.\n",
    "model = keras.Sequential()\n",
    "model.add(Conv2D(64, 5, 2, activation = \"relu\", input_shape = (64, 64, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, 3, 2, activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation = \"relu\"))\n",
    "model.add(Dense(17, activation = \"sigmoid\"))\n",
    "#train the model\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [fbeta])\n",
    "model.fit(x_train, y_train, validation_data = (x_val, y_val), epochs = 20, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test, batch_size = 128) #Make predictions on the test set\n",
    "pred = pd.DataFrame(predictions, columns =  tag_list) #Create a data frame of predictions with the tags as column names\n",
    "\n",
    "#Write a loop to assign each value to its predicted label\n",
    "preds = []\n",
    "for i in tqdm(range(pred.shape[0]), miniters=1000):\n",
    "    a = pred.iloc[[i]]\n",
    "    a = a.apply(lambda x: x > 0.2, axis=1)\n",
    "    a = a.transpose()\n",
    "    a = a.loc[a[i] == True]\n",
    "    ' '.join(list(a.index))\n",
    "    preds.append(' '.join(list(a.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['tags'] = preds #Assign the predictions to the tags column of the df_test data frame\n",
    "df_test.to_csv('Submission.csv', index = False) #Export to csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
